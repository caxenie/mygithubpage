<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Sandbox: research, tech, dev by Cristian Axenie</title>
    <meta name="description" content="Artificial Intelligence, neurorobotics, Big Data, computational neuroscience, embedded systems, and hacks.">
  </head>

  <body>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="welcome-to-my-sandbox" class="anchor" href="#welcome-to-my-sandbox" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sandbox: research, tech, dev.</strong>
</h1>

<h2>
<a id="a-messy-place-to-store-opinions-work-and-all-sorts-of-ideas-on-AI-neuroscience-neural-engineering-big-data-robotics-and-coding" class="anchor" href="#a-messy-place-to-store-opinions-work-and-all-sorts-of-ideas-on-neuroscience-neural-engineering-robotics-and-coding" aria-hidden="true"><span class="octicon octicon-link"></span></a>A collection of projects of all sorts and ideas on: Artificial Intelligence, neuroscience, neural engineering, Big Data, robotics and coding.</h2>

<p>My name is Cristian Axenie and I am a Senior Research Engineer in Artificial Intelligence and Machine Learning for Streaming Big Data at the Huawei European Research Center in Munich. </p> 

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/HERC.png" alt=""></p>

<p>I also lead the AKII Microlab (AI and VR Tech Focus) within the AUDI Konfuzius Ingolstadt Institute Ingolstadt (<a href="http://audi-konfuzius-institut-ingolstadt.de/forschung/akii-microlab.html">http://audi-konfuzius-institut-ingolstadt.de/forschung/akii-microlab.html</a>) and Lecturer in Artificial Intelligence and Machine Learning at the Technical University of Ingolstadt.  (<a href="http://www.thi.de">http://www.thi.de</a>).</p>
		
<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/AKII.png" style="float: left; width: 30%; margin-right: 1%; margin-bottom: 0.5em;" alt=""></p>
				
<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/thi.png" style="float: left; width: 30%; margin-right: 1%; margin-bottom: 0.5em;" alt=""></p>

<p style="clear: both;">
	
<p> A short vita and publications list:</p>
<p>(<a href="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/CristianAXENIE-CurriculumVitae.pdf">Curriculum Vitae</a>)</p>
		
<p>Previously I was a postdoctoral research fellow with the Neuroscientific System Theory Group (<a href="http://www.nst.ei.tum.de">http://www.nst.ei.tum.de</a>) at Technische Universität München (<a href="http://www.tum.de">http://www.tum.de</a>), somewhere in south Germany. </p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure_me.png" style="float: left; width: 30%; margin-right: 1%; margin-bottom: 0.5em;" width="50%" height="50%" alt=""> </p>
	
<p> <img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure0.png" style="float: left; width: 30%; margin-right: 1%; margin-bottom: 0.5em;" width="50%" height="50%" alt=""> </p>

<p style="clear: both;">
	
<p>After following a robotics and control engineering track during my undergraduate studies, I have switched my focus towards intelligent, brain-inspired processing algorithms.
In 2011 I have joined the Neuroscientific System Theory Group led by Prof. Conradt. This group's research direction is to understand information processing in neural systems, develop novel algorithms inspired by brain functionality and to transfer these into technical systems.</p>

<p> Thesis download link:</p>
<p>(<a href="https://mediatum.ub.tum.de/download/1284085/1284085.pdf">PDF</a>)</p>

<hr>

<h2>
<a id="research" class="anchor" href="#research" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Research</strong>
</h2>

<hr>

<h3>
<a id="adaptive sensorimotor control" class="anchor" href="#adaptive-senosorimotor-control" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adaptive Neuromorphic Sensorimotor Control </h3>

<p> Efficient sensorimotor processing is inherently driven by physical real-world constraints that an acting agent faces in its environment. Sensory streams contain certain statistical dependencies determined by the structure of the world, which impose constraints on a system’s sensorimotor affordances. </p>
<p> This limits the number of possible sensory information patterns and plausible motor actions. Learning mechanisms allow the system to extract the underlying correlations in sensorimotor streams.</p>
<p> This research direction focused on the exploration of sensorimotor learning paradigms for embedding adaptive behaviors in robotic system and demonstrate flexible control systems using neuromorphic hardware and neural-based adaptive control. I employed large-scale neural networks for gathering and processing complex sensory information, learning sensorimotor contingencies, and providing adaptive responses. </p>
<p> To investigate the properties of such systems, I developed flexible embodied robot platforms and integrate them within a rich tool suite for specifying neural algorithms that can be implemented in embedded neuromorphic hardware.</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/neurobot1.png" alt=""></p>
		
<p> The mobile manipulator I developed at NST for adaptive sensorimotor systems consists of an omni-directional (holonomic) mobile manipulation platform with embedded low-level motor control and multimodal sensors. </p> 
<p> The on-board micro-controller receives desired commands via WiFi and continuously adapts the platform's velocity controller. The robot’s integrated sensors include wheel encoders for estimating odometry, a 9DoF inertial measurement unit, a proximity bump-sensor ring and three event-based embedded dynamic vision sensors (eDVS) for visual input.</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/neurobot2.png" alt=""></p>
		
<p>The mobile platform carries an optional 6 axis robotic arm with a reach of >40cm. This robotic arm is composed of a set of links connected together by revolute joints and allows lifting objects of up to 800 grams. The mobile platform contains an on-board battery of 360 Wh, which allows autonomous operation for well above 5h. </p>
	
<a id="publications" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h3>

<h3>
<a id="peer-reviewed-journal-papers" class="anchor" href="#peer-reviewed-journal-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peer reviewed journal papers</h3>

<p>F. Mirus, C. Axenie, T. C. Stewart, J. Conradt, Neuromorphic Sensorimotor Adaptation for Robotic Mobile Manipulation: From Sensing to Behaviour, Cognitive Systems Research, 2017 (in review)</p>

<h3>
<a id="synthesis-of-distributed-cognitive-systems---learning-and-development-of-multisensory-integration" class="anchor" href="#synthesis-of-distributed-cognitive-systems---learning-and-development-of-multisensory-integration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Synthesis of Distributed Cognitive Systems - Learning and Development of Multisensory Integration</h3>

<p>My research interest is in developing sensor fusion mechanisms for robotic applications. In order to extend the interacting areas framework a second direction in my research focuses on learning and development mechanisms.</p>

<p>Human perception improves through exposure to the environment. A wealth of sensory streams which provide a rich experience continuously refine the internal representations of the environment and own state. Furthermore, these representations determine more precise motor planning.</p>

<p>An essential component in motor planning and navigation, in both real and artificial systems, is egomotion estimation. Given the multimodal nature of the sensory cues, learning crossmodal correlations improves the precision and flexibility of motion estimates.</p>

<p>During development, the biological nervous system must constantly combine various sources of information and moreover track and anticipate changes in one or more of the cues. Furthermore, the adaptive development of the functional organisation of the cortical areas seems to depend strongly on the available sensory inputs, which gradually sharpen their response, given the constraints imposed by the cross-sensory relations.</p>

<p>Learning processes which take place during the development of a biological nervous system enable it to extract mappings between external stimuli and its internal state. Precise egomotion estimation is essential to keep these external and internal cues coherent given the rich multisensory environment. In this work we present a learning model which, given various sensory inputs, converges to a state providing a coherent representation of the sensory space and the cross-sensory relations.</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure1.png" width="120%" height="120%" alt="Figure 1"></p>

<p>The model is based on Self-Organizing-Maps and Hebbian learning (see Figure 1) using sparse population coded representations of sensory data. The SOM is used to represent the sensory data, while the Hebbian linkage extracts the coactivation pattern given the input modalitites eliciting peaks of activity in the neural populations. The model was able to learn the intrinsic sensory data statistics without any prior knowledge (see Figure 2).</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure2.png" width="120%" height="120%" alt="Figure 2"></p>

<p>The developed model, implemented for 3D egomotion estimation on a quadrotor, provides precise estimates for roll, pitch and yaw angles (setup depicted in Figure 3a, b).</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure3.png" alt="Figure 3"></p>

<p>Given relatively complex and multimodal scenarios in which robotic systems operate, with noisy and partially observable environment features, the capability to precisely and timely extract estimates of egomotion critically influences the set of possible actions.</p>

<p>Utilising simple and computationally effective mechanisms, the proposed model is able to learn the intrinsic correlational structure of sensory data and provide more precise estimates of egomotion (see Figure 4a, b).</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure4.png" alt="Figure 4"></p>

<p>Moreover, by learning the sensory data statistics and distribution, the model is able to judiciously allocate resources for efficient representation and computation without any prior assumptions and simplifications. Alleviating the need for tedious design and parametrisation, it provides a flexible and robust approach to multisensory fusion, making it a promising candidate for robotic applications.</p>

<h3>
<a id="publications" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h3>

<h3>
<a id="peer-reviewed-journal-papers" class="anchor" href="#peer-reviewed-journal-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peer reviewed journal papers</h3>

<p>I. Sugiarto, C. Axenie, J. Conradt, High Level Synthesis and Optimization of a Hardware Accelerator for an Embedded Factor Graph, ACM Transactions on Embedded Computing Systems (2016) </p>
		
<p>C. Axenie, C. Richter, J. Conradt, A Self-Synthesis Approach to Perceptual Learning for Multisensory Fusion in Robotics, Sensors Journal, 2016 (<a href="http://www.mdpi.com/1424-8220/16/10/1751">PDF</a>) </p>

<h3>
<a id="peer-reviewed-conference-papers" class="anchor" href="#peer-reviewed-conference-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peer reviewed conference papers</h3>

<p>C. Axenie, J. Conradt, Learning Sensory Correlations for 3D Egomotion Estimation, International Conf. on Biomimetics and Biohybrid Systems, 2015</p>

<h3>
<a id="poster-presentations" class="anchor" href="#poster-presentations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Poster presentations</h3>

<p>C. Axenie, J. Conradt, A model for development and emergence in multisensory integration, Bernstein Conference on Computational Neuroscience, Göttingen, 2014. (<a href="http://www.nst.ei.tum.de/fileadmin/w00bqs/www/pdf/papers_axenie/2014_BCCN_Axenie_Conradt.pdf">PDF</a>)</p>

<hr>

<h3>
<a id="synthesis-of-distributed-cognitive-systems---interacting-cortical-maps-for-environmental-interpretation" class="anchor" href="#synthesis-of-distributed-cognitive-systems---interacting-cortical-maps-for-environmental-interpretation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Synthesis of Distributed Cognitive Systems - Interacting Cortical Maps for Environmental Interpretation</h3>

<p>The core focus of my research interest is in developing sensor fusion mechanisms for robotic applications. These mechanisms enable a robot to obtain a consistent and global percept of its environment using available sensors by learning correlations between them in a distributed processing scheme inspired by cortical mechanisms.</p>

<p>Environmental interaction is a significant aspect in the life of every physical entity, which allows the updating of its internal state and acquiring new behaviors. Such interaction is performed by repeated iterations of a perception-cognition-action cycle, in which the entity acquires and memorizes relevant information from the noisily and partially observable environment, to develop a set of applicable behaviors (see Figure 5). </p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure5.png" alt="Figure 5"></p>

<p>This recently started research project is in the area of mobile robotics; and more specifically in explicit methods applicable for acquiring and maintaining such environmental representations. State-of-the-art implementations build upon probabilistic reasoning algorithms, which typically aim at optimal solutions with the cost of high processing requirements.</p>

<p>In this project I am developing an alternative, neurobiologically inspired method for real-time interpretation of sensory stimuli in mobile robotic systems: a distributed networked system with inter-merged information storage and processing that allows efficient parallel reasoning. This networked architecture will be comprised of interconnected heterogeneous software units, each encoding a different feature about the state of the environment that is represented by a local representation (see Figure 6). </p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure6.png" alt="Figure 6"></p>

<p>Such extracted pieces of environmental knowledge interact by mutual influence to ensure overall system coherence. A sample instantiation of the developed system focuses on mobile robot heading estimation (see Figure 7). In order to obtain a robust and unambiguous description of robot’s current orientation within its environment inertial, proprioceptive and visual cues are fused (see image). Given available sensory data, the network relaxes to a globally consistent estimate of the robot's heading angle and position.</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure7.png" alt="Figure 7"></p>

<h3>
<a id="publications-1" class="anchor" href="#publications-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h3>

<h3>
<a id="journal-articles" class="anchor" href="#journal-articles" aria-hidden="true"><span class="octicon octicon-link"></span></a>Journal articles</h3>

<p>I. Sugiarto, C. Axenie, J. Conradt, From Adaptive Reasoning to Cognitive Factory: Bringing Cognitive Intelligence to Manufacturing Technology, International Journal of Industrial Research and Applied Engineering (2016) (<a href="http://jirae.petra.ac.id/index.php/jirae/article/view/19317">PDF</a>)</p>

<p>I. Susnea, C. Axenie, Cognitive Maps for Indirect Coordination of Intelligent Agents, Studies in Informatics and Control Vol. 24 (2015) (<a href="http://sic.ici.ro/?page_id=632">PDF</a>)</p>

<p>C. Axenie, J. Conradt, Cortically inspired sensor fusion network for mobile robot egomotion estimation, Robotics and Autonomous Systems (2014) (<a href="http://www.sciencedirect.com/science/article/pii/S0921889014003133">PDF</a>) </p>

<h3>
<a id="peer-reviewed-conference-papers-1" class="anchor" href="#peer-reviewed-conference-papers-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peer reviewed conference papers</h3>

<p>C. Axenie, J. Conradt, Cortically Inspired Sensor Fusion Network for Mobile Robot Heading Estimation, International Conf. on Artificial Neural Networks (ICANN), 2013, pp. 240-47. (<a href="http://link.springer.com/chapter/10.1007/978-3-642-40728-4_30">PDF</a>) </p>

<h3>
<a id="poster-presentations-1" class="anchor" href="#poster-presentations-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Poster presentations</h3>

<p>C. Axenie, M. Firouzi, M.Mulas, J. Conradt, Multimodal sensor fusion network for mobile robot egomotion estimation, Bernstein Conference on Computational Neuroscience, Göttingen, 2014. (<a href="http://www.nst.ei.tum.de/fileadmin/w00bqs/www/pdf/papers_axenie/2014_BCCN_Axenie_Firouzi_Mulas_Conradt.pdf">PDF</a>) </p>

<p>M. Firouzi, C. Axenie, J. Conradt, Multi-sensory cue integration with reliability encoding, using Line Attractor Dynamics, searching for optimality, Bernstein Conference on Computational Neuroscience, Göttingen, 2014. (<a href="http://www.nst.ei.tum.de/fileadmin/w00bqs/www/pdf/papers_axenie/2014_BCCN_Firouzi_Axenie_Conradt.pdf">PDF</a>)</p>

<p>C. Axenie, M. Firouzi, J. Conradt, Multisensory Integration Network for Mobile Robot Self-motion Estimation, Bernstein Conference on Computational Neuroscience, Tübingen, 2013. (<a href="http://www.nst.ei.tum.de/fileadmin/w00bqs/www/pdf/papers_axenie/2013-SparksWS_Axenie_Firouzi_Conradt.pdf">PDF</a>)</p>

<p>C. Axenie, J. Conradt, Synthesis of Distributed Cognitive Systems: Interacting Maps for Sensor Fusion, Bernstein Conference on Computational Neuroscience, München, 2012. (<a href="http://www.nst.ei.tum.de/fileadmin/w00bqs/www/pdf/papers_axenie/2012-BCCN_Axenie_Conradt.pdf">PDF</a>)</p>

<hr>

<h3>
<a id="adaptive-nonlinear-control-algorithm-for-fault-tolerant-robot-navigation" class="anchor" href="#adaptive-nonlinear-control-algorithm-for-fault-tolerant-robot-navigation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adaptive Nonlinear Control Algorithm for Fault Tolerant Robot Navigation</h3>

<p>Today’s trends in control engineering and robotics are blending gradually into a slightly challenging area, the development of fault tolerant real-time applications. Hence, applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances. The fault tolerant behavior in mobile robots refers to the possibility to autonomously detect and identify faults as well as the capability to continue operating after a fault occurred. This work introduces a real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots (see Figure 8).</p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure8.png" alt="Figure 8"></p>

<iframe width="420" height="315" src="https://www.youtube.com/embed/UkgOAOTyQCQ" frameborder="0" allowfullscreen></iframe>

<p>Furthremore, the application was extended to introduce a novel implementation for limited sensor mobile robots environment mapping. The developed algorithm is a SLAM implementation. It uses real time data acquired from the sonar ring and uses this information to feed the mapping module for offline mapping (see Figure 9). </p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure9.png" alt="Figure 9"></p>

<p>The latter is running on top of the real time fault tolerant control application for mobile robot trajectory tracking operation (see Figures 10, 11). </p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure10.png" alt="Figure 10"></p>

<p><img src="https://raw.githubusercontent.com/caxenie/neurorobotics.me_backend/master/pics/figure11.png" alt="Figure 11"></p>

<p>Along the developed application, the mechanical design, electronics design and implementation were made as part of the BA and MA thesis projects.</p>

<h3>
<a id="publications-2" class="anchor" href="#publications-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h3>

<h3>
<a id="peer-reviewed-conference-papers-2" class="anchor" href="#peer-reviewed-conference-papers-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peer reviewed conference papers</h3>

<p>Axenie Cristian, Stancu Alexandru, Zanoschi Aurelian, Pascalin Andrei, Perjeru Marius, Maftei Florentina, A Client-Server Based Real-Time Control Tool for Complex Distributed Systems, Proc. of 9th Real-Time Linux Workshop, Linz, Austria, November 2007 (<a href="https://www.osadl.org/fileadmin/events/rtlws-2007/Axenie.pdf">PDF</a>)</p>

<p>Cristian Axenie, “Mobile Robot Fault Tolerant Control. Introducing ARTEMIC.” In the 9th International Conference on Signal Processing, Robotics and Automation WSEAS Conference Proceedings Included in ISI/SCI Web of Science and Web of Knowledge, University of Cambridge, UK, February 2010 (<a href="http://www.wseas.us/e-library/conferences/2010/Cambridge/ISPRA/ISPRA-34.pdf">PDF</a>)</p>

<p>Cristian Axenie, “A New Approach in Mobile Robot Fault Tolerant Control. Minimizing Costs and Extending Functionality”, Included in ISI / SCI (Web of Science) WSEAS TRANSACTIONS ON SYSTEMS AND CONTROL 2010 (<a href="http://www.wseas.us/e-library/transactions/control/2010/89-464.pdf">PDF</a>)</p>

<p>Cristian Axenie, Cernega Daniela, “Mobile Robot Fault Tolerant Control”, IEEE/IACSIT ICIEE 2010 (International Conference on Information and Electronics Engineering), Shanghai, China, June 2010 (<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5529958&amp;filter%3DAND%28p_IS_Number%3A5529772%29">PDF</a>)</p>

<p>Cristian Axenie, Cernega Daniela, “ Adaptive Sliding Mode Controller Design for Mobile Robot Fault Tolerant Control”, 19th  IEEE International Workshop on Robotics in Alpe-Adria-Danube Region, Budapest, Hungary, June 2010 (<a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=5524575&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5524575">PDF</a>)</p>

<p>Cristian Axenie, Razvan Solea, “Real Time Control Design for Mobile Robot Fault Tolerant Control”, 2010 IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications, July 15-17, 2010, Qingdao, ShanDong, China (<a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=5552026&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F5547546%2F5551988%2F05552026.pdf%3Farnumber%3D5552026">PDF</a>) </p>

<hr>
        </section>

        <aside id="sidebar">
          <h2>Latest News</h2>
	<h3>October 2017</h3>
	<p>Joined the AUDI Konfuzius Institute Ingolstadt to lead the AKII Microlab and apply AI and ML to VR. </p>			
	<h3>October 2017</h3>
	<p>Joined the Technical University of Ingolstadt as Lecturer in Artificial Intelligence and Machine Learning. </p>			
	<h3>April 2017</h3>
	<p>Joined the Huawei European Research Center as Senior Research Engineer to lead work on online Machine Learning for Big Data. </p>			
	<h3>March 2017</h3>
	<p>Invited talk at TEDx - Calea Domneasca 18.03.2017 (http://www.ted.com/tedx/events/21484), Theme: Dare to leave a mark in Galati, Romania. </p>			
	<h3>January 2017</h3>
	<p>Microsoft Faculty Connection coverage (goo.gl/uPWGna) for project demo at Hack Cambridge 2017, 28 – 29 January 2017, University of Cambridge with a Real-time Event-based Vision Monitoring and Notification System for Seniors and Elderly using Neural Networks.</p>	
	<h3>January 2017</h3>
	<p>Awarded a BayIntAn Fellowship (5000 EUR) by the Bavarian Research Alliance for establishing a cooperation on the development of a platform for neuromorphic models of sensorimotor adaptation with ETH Zurich, Switzerland and University of California, Irvine, US.</p>
	<h3>January 2017</h3>
	<p>Guest lecturer in Neural Computation at BaseCamp winter school in Wien. An immersive full-time program for prospective data scientists to deepen theoretical knowledge and enhance practical skills for data analytics.</p>
	<h3>January 2017</h3>
	<p>Best innovation idea at the ANDRITZ Pioneers Hackaton innovating for the international technology group ANDRITZ. Developed an artificial neural learning agent for automation process productivity enhancement.</p>
	<h3>July 2016</h3>
	<p>Awarded a BayIntAn Fellowship (10000EUR) by the Bavarian Research Alliance for establishing a cooperation on neurorobotics with University of Waterloo, Canada and the University of Manchester, UK.</p>
        <h3>June 2016</h3>
        WIRED UK coverage (http://goo.gl/5yQ1Fn) at the Hack the Senses hackathon in London:
	How to hack your senses: from 'seeing' sound to 'hair GPS':
	
	"Two-man team HearSee built a headband that taps into synaesthesia, translating changes in frameless video to sound allowing blind people or those with weak vision to see motion. Roboticist and neurologist Cristian Axenie assembled the hardware in mere minutes – attaching a pair of cameras and wires to a terrycloth headband."
      	<h3>April 2016</h3>
      	<p>Awarded 1st prize (team) at the Daimler Financial Services Big Data Analytics Hackaton for the design of a neurofuzzy learning system for anomaly detection and user interaction in big data streams.</p>
      	<h3>April 2016</h3>
      	<p>Awarded special Microsoft Cognitive Technologies prize at the Burda Hackdays for the design of a neural learning system for inferring role assignments in working teams using psychometric data analytics.</p>
      	<h3>April 2016</h3>
      	<p>Awarded PhD (Summa cum Laude) degree in Neuroscience and Robotics from the Technical University of Munich.</p>
      	<h3>March 2016</h3>
      	<p>Awarded 1st prize (team) in the BMW Automotive Hackdays for the design of an inference system for driving profile learning and recommendation for skills improvement and predictive maintenance in car-sharing.</p>
	<h3>July 2013</h3>
      	<p>Awarded the Convergent Science Network of Biomimetic and Biohybrid Systems Research Fellowship for the 2013 Telluride Neuromorphic Cognition Engineering Workshop.</p>
	<h3>May 2013</h3>
      	<p>Awarded the Convergent Science Network of Biomimetic and Biohybrid Systems Research Fellowship for the 2013 CapoCaccia Cognitive Neuromorphic Engineering Workshop.</p>
	<h3>April 2013</h3>
      	<p>Awarded the Leonhard Lorenz-Stiftung Scholarship for novel ideas in research.</p>
	<h3>April 2012</h3>
      	<p>Awarded the Bavarian Elite Research Scholarship by the Bavarian State Ministry of Sciences, Research and the Arts.</p>
	<h3>September 2009</h3>
      	<p>4th place at the National IBM “Best Linux Application” programming contest for work in robot fault-tolerant control using custom embedded Linux.</p>
	<h3>May 2009</h3>
      	<p>Best paper award at the 13th International Scientific Sessions ZTS, UPT (Romania) for work on nonlinear control for mobile robots.</p>
	<h3>September 2008</h3>
      	<p>Designer certificate on dependable embedded systems analysis and design from University of Lucern (Switzerland).</p>
	<h3>June 2008</h3>
      	<p>Invited talk at International Student Scientific Sessions of the Military Technical Academy (Romania) for work on adaptive systems design.</p>
	<h3>November 2007</h3>
      	<p>Invited presentation at the 9th Real-Time Linux Workshop (Austria) for work on real-time control in distributed systems.</p>
      	
          <iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="http://colmdoyle.github.io/gh-activity/gh-activity.html?user=caxenie&type=user" width="360" height="600">Current projects</iframe>
          <iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=fusion-maps-analyzer&type=repo" width="360" height="350"></iframe>
        <iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=fusion-maps-analyzer&type=repo" width="360" height="350"></iframe>
	<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=fusion-maps-population-code&type=repo" width="360" height="450"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=sensory-projections-som&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=dev-sensor-fusion-net&type=repo" width="360" height="450"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=developing-fusion-network-fast&type=repo" width="360" height="450"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=corr-learn-som-quadrotor&type=repo" width="360" height="450"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=fusion-maps-analyzer-matlab&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=corr-learn-som-fast&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=fuzzy-ctrl-demo&type=repo" width="360" height="250"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=sharp-learning&type=repo" width="360" height="250"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=unsupervised-relation-learning&type=repo" width="360" height="250"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=sigma-pi-som-learning&type=repo" width="360" height="250"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=ibfn-net-cue-integration&type=repo" width="360" height="250"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=hopfield-memory-demo&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=hopfield-distort-demo&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=gas-tsp-demo&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=gas-antenna-demo&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=dynamic-association-net&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=gas-opt-demo&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=ip-camera-overhead-tracker&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=spartan6-linux-dev&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=embedded-ser2eth-converter&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=msp430-android-gyro-acc-tester&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=artemic&type=repo" width="360" height="350"></iframe>
<iframe allowtransparency="true" frameborder="0" scrolling="yes" seamless="seamless" src="https://caxenie.github.io/github-state-widget.html?user=caxenie&repo=nst_drone_full_infrastructure&type=repo" width="360" height="350"></iframe>
        </aside>
      </div>
    </div>

  	<script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-65891127-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
          
  </body>
</html>

